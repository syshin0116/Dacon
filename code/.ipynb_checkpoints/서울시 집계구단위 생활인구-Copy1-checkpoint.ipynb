{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed1997fd-c560-4f88-bd53-75e2c226ba28",
   "metadata": {},
   "source": [
    "# ì„œìš¸ì‹œ ìƒí™œì¸êµ¬\n",
    "## ì„œìš¸ ìƒí™œì¸êµ¬ í˜„í™© (2022.09.28. ê¸°ì¤€)\n",
    "### url: https://data.seoul.go.kr/dataVisual/seoul/seoulLivingPopulation.do\n",
    "\n",
    "1. ì§‘ê³„êµ¬ ë‹¨ìœ„ ì„œìš¸ ìƒí™œì¸êµ¬(ë‚´êµ­ì¸)\n",
    "    - url: https://data.seoul.go.kr/dataList/OA-14979/F/1/datasetView.do\n",
    "    - ì„¤ëª…: ì„œìš¸ì‹œê°€ ë³´ìœ í•œ ê³µê³µë°ì´í„°ì™€ í†µì‹ ë°ì´í„°ë¡œ ì¸¡ì •í•œ íŠ¹ì •ì‹œì ì— ì„œìš¸ì˜ íŠ¹ì • ì§€ì—­ì— ì¡´ì¬í•˜ëŠ” ì¸êµ¬ ì¤‘ ë‚´êµ­ì¸\n",
    "\n",
    "<!-- <br> -->\n",
    "\n",
    "\n",
    "2. ì§‘ê³„êµ¬ ë‹¨ìœ„ ì„œìš¸ ìƒí™œì¸êµ¬(ì¥ê¸°ì²´ë¥˜ ì™¸êµ­ì¸)\n",
    "    - url: https://data.seoul.go.kr/dataList/OA-14978/F/1/datasetView.do\n",
    "    - ì„¤ëª…:ì„œìš¸ì‹œê°€ ë³´ìœ í•œ ê³µê³µë°ì´í„°ì™€ í†µì‹ ë°ì´í„°ë¡œ ì¸¡ì •í•œ íŠ¹ì •ì‹œì ì— ì„œìš¸ì˜ íŠ¹ì • ì§€ì—­ì— ì¡´ì¬í•˜ëŠ” ì¸êµ¬ ì¤‘ ì¥ê¸°ì²´ë¥˜ ì™¸êµ­ì¸\n",
    "\n",
    "<!-- <br> -->\n",
    "\n",
    "\n",
    "3. ì§‘ê³„êµ¬ ë‹¨ìœ„ ì„œìš¸ ìƒí™œì¸êµ¬(ë‹¨ê¸°ì²´ë¥˜ ì™¸êµ­ì¸)\n",
    "    - url: https://data.seoul.go.kr/dataList/OA-14980/F/1/datasetView.do\n",
    "    - ì„¤ëª…:ì„œìš¸ì‹œê°€ ë³´ìœ í•œ ê³µê³µë°ì´í„°ì™€ í†µì‹ ë°ì´í„°ë¡œ ì¸¡ì •í•œ íŠ¹ì •ì‹œì ì— ì„œìš¸ì˜ íŠ¹ì • ì§€ì—­ì— ì¡´ì¬í•˜ëŠ” ì¸êµ¬ ì¤‘ ë‹¨ê¸°ì²´ë¥˜ ì™¸êµ­ì¸\n",
    "\n",
    "<!-- <br> -->\n",
    "\n",
    "\n",
    "\n",
    "â€» ê°œì¸ì •ë³´ ë¹„ ì‹ë³„í™”ë¥¼ ìœ„í•˜ì—¬ â€˜3ëª…â€™ ì´í•˜ì¸ ê²½ìš° â€œ * â€ ì²˜ë¦¬\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82b072bd-5353-4b29-8326-8454d6486ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "import urllib.request\n",
    "import logging\n",
    "logger = logging.getLogger('my_logger')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4298b9cf-0c72-4b31-9d4b-04862dde0e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logging.basicConfig()\n",
    "\n",
    "logger.debug('This is my ğŸ˜‚ debug message ')\n",
    "logger.info('This is my ğŸ’œ info message ')\n",
    "# logger.error('This is my error ğŸ˜±message ')\n",
    "# logger.critical('This is my ğŸ˜­ critical message ')presence_of_element_located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "423a6eec-9b7e-42f7-85e1-9548c1a7b67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í¬ë¡¬ë“œë¼ì´ë²„ ì €ë™ ë‹¤ìš´ë¡œë“œ (ë²„ì „ì— ë§ì¶°ì„œ)\n",
    "# !pip install chromedriver-autoinstaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93865239-f073-4e26-8d32-7e35fa0ecb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "## downloads a zipped tar file (.tar.gz) that contains several CSV files, \n",
    "## from a public website. \n",
    "def download_and_merge_csv(url: str, down_dir: str, output_csv: str):\n",
    "    \"\"\"\n",
    "    - url: url address from which you want to download a compressed file\n",
    "    - down_dir: directory to which you want to download a compressed file\n",
    "    - output_csv: a file name of a exported DataFrame using pd.to_csv() method\n",
    "    \"\"\"\n",
    "    \n",
    "    # if down_dir does not exists, then create a new directory\n",
    "    down_dir = 'downloaded_data'\n",
    "    if os.path.isdir(down_dir):\n",
    "        pass\n",
    "    else:\n",
    "        os.mkdir(down_dir)\n",
    "        \n",
    "    # Open for reading with gzip compression.\n",
    "    # Extract all members from the archive to the current working directory or directory path. \n",
    "    with urllib.request.urlopen(url) as res:\n",
    "        tarfile.open(fileobj=res, mode=\"r|gz\").extractall(down_dir)\n",
    "    \n",
    "    # concatenate all extracted csv files\n",
    "    df = pd.concat(\n",
    "        [pd.read_csv(csv_file, header=None) \n",
    "         for csv_file in glob.glob(os.path.join(down_dir, '*.csv'))])\n",
    "    \n",
    "    # export a DataFrame to a csv file\n",
    "    df.to_csv(output_csv, index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4b1ad9-b237-4385-9ac1-9eb4f5ae9a9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f95bc2e-49dd-4865-a706-489ff535bb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import chromedriver_autoinstaller\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70af773b-f0cc-43f4-80eb-e1ed40a0d05e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/syshin/miniforge3/envs/tensorflow/lib/python3.9/site-packages/chromedriver_autoinstaller/106/chromedriver'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chromedriver_autoinstaller.install()  # Check if the current version of chromedriver exists\n",
    "                                      # and if it doesn't exist, download it automatically,\n",
    "                                      # then add chromedriver to path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "777104a3-ddb6-4930-96e4-04a8257a7647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec0b9a26-d48d-4b30-b44a-84d4ae4ba054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def page_has_loaded():\n",
    "#     logger.warning(\"Checking if {} page is loaded.\".format(driver.current_url))\n",
    "#     page_state = driver.execute_script('return document.readyState;')\n",
    "#     return page_state == 'complete'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a065ad-46d7-40b4-b211-01296e339bcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7bb6b66c-2256-426e-bda4-8533aae4bbb7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. ì§‘ê³„êµ¬ ë‹¨ìœ„ ì„œìš¸ ìƒí™œì¸êµ¬(ë‚´êµ­ì¸)\n",
    "    - a)2022ë…„ 01ì›”~08ì›”\n",
    "    - b)2019ë…„, 2020ë…„, 2021ë…„"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9454dc2-eddc-4fc6-8d09-387c6b031dfe",
   "metadata": {},
   "source": [
    "### a) 2022ë°ì´í„° ë‹¤ìš´ë¡œë“œ\n",
    "- 1ì›”~08ì›” ë°ì´í„°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7e9961c-94d5-4205-8f3e-850117b94052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['202201',\n",
       " '202202',\n",
       " '202203',\n",
       " '202204',\n",
       " '202205',\n",
       " '202206',\n",
       " '202207',\n",
       " '202208']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_date_list = []\n",
    "for i in range(1, 9):\n",
    "    download_date_list.append(\"2022\"+f\"{i:02d}\")\n",
    "download_date_list    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecbc0ae6-4b55-4d70-847e-af29898e6f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloadFile(202201\n",
      "downloadFile(202202\n",
      "downloadFile(202203\n",
      "downloadFile(202204\n",
      "downloadFile(202205\n",
      "downloadFile(202206\n",
      "downloadFile(202207\n",
      "downloadFile(202208\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "url = \"https://data.seoul.go.kr/dataList/OA-14979/F/1/datasetView.do#\"\n",
    "driver.get(url)\n",
    "\n",
    "element = WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"#listDownload > a > span\")))\n",
    "for i in download_date_list:\n",
    "    driver.execute_script(\"downloadFile({0})\".format(i))\n",
    "    print(\"downloadFile({0})\".format(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bed3b3-b92e-4ace-a604-5efc892f8cba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
